{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# square_feet = r'.*\\s+([0-9]+)\\xa0ft*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 没有user-agent被屏蔽率100%， 有这个有可能不会被屏蔽\n",
    "driver = webdriver.Chrome()\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('headless')\n",
    "chrome_options.add_argument('user-agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36\"')\n",
    "\n",
    "# driver.get('https://google.com')\n",
    "# driver.get('https://streeteasy.com')\n",
    "# time.sleep(3)\n",
    "# sales = driver.find_element_by_name('signin')\n",
    "# sales.click()\n",
    "# time.sleep(5)\n",
    "# user = driver.find_element_by_id('login')\n",
    "# user.send_keys('jojo199619@gmail.com')\n",
    "# pw = driver.find_element_by_id('password')\n",
    "# pw.send_keys('jojo199619')\n",
    "# driver.find_element_by_name('do_login').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('Sales_SE.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_sub = data[:3129]\n",
    "# data_sub = data[3129:3129*2]\n",
    "# data_sub = data[3129*2:3129*3]\n",
    "data_sub = data[3129*3:] # Jieyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1824"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniq_add = data_sub['address'].unique()\n",
    "len(uniq_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# agent = driver.execute_script(\"return navigator.userAgent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import unicodedata\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.common.exceptions import TimeoutException\n",
    "# from selenium.webdriver.common.by import By\n",
    "\n",
    "# driver = webdriver.Chrome()\n",
    "# chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('user-agent=\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36\"')\n",
    "# driver.get('https://streeteasy.com/building/311-east-3-street-new_york')\n",
    "# # driver.get('https://streeteasy.com/for-sale/nyc/?lnf=old')\n",
    "\n",
    "# #i=2  \n",
    "# #while i > 0: # while loop code\n",
    "# name = []\n",
    "# rent= []\n",
    "# type1= []\n",
    "# url=[]\n",
    "\n",
    "# # This portion scrapes the rental listing pages one by one and colelcts details of rent, name and Urls for 18000+ listings\n",
    "\n",
    "\n",
    "# for i in range(3):\n",
    "#     delay = 5 # seconds\n",
    "#     try:\n",
    "# #         wait = WebDriverWait(driver, 5)\n",
    "#         time.sleep(5)\n",
    "# #         sales = driver.find_element_by_id('all_past_sales')\n",
    "# #         sales.click()\n",
    "# #         wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'listing_block loaded')))\n",
    "# #         time.sleep(5)\n",
    "#         print(\"Page is ready!\")\n",
    "# #         sales = driver.find_element_by_id('all_past_sales')\n",
    "# #         sales.click()\n",
    "# #         WebDriverWait(driver, delay).until(EC.presence_of_element_located(driver.find_element_by_class_name('next')))\n",
    "#         html_doc = driver.page_source\n",
    "#     except Exception as e:\n",
    "#         print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def antibot(source):\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "    if 'CAPTCHA' in soup.text:\n",
    "        print('Ops...I am recognized as a robot. QAQ (Maybe changing IP by using NYU vpn would help...)')\n",
    "        return True\n",
    "#     elif 'Unfortunately' in soup.text:\n",
    "#         print('Streeteasy, I know it is you! Pass the robot check by a normal browser.')\n",
    "#         return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RobotError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class AddressInfo(object):\n",
    "#     def __init__(self, address):\n",
    "#         for url in search(address+'streeteasy', stop=3):\n",
    "#             print(url)\n",
    "#             if 'streeteasy' in url and 'building' in url and (url[-8:]=='new_york' or url[-9:]=='manhattan'):\n",
    "#                 qualified = url\n",
    "#                 print(address, qualified)\n",
    "#                 break\n",
    "#         if 'qualified' not in locals():\n",
    "#             print('OMG! Why the building name changed! I have to startover! Give me a few seconds...')\n",
    "#             for url in search(address+'streeteasy', stop=3):\n",
    "#                 print(url)\n",
    "#                 if 'streeteasy' in url and 'building' in url:\n",
    "#                     qualified = url\n",
    "#                     print(address, ':', qualified)\n",
    "#                     break\n",
    "#         self.url = qualified\n",
    "                \n",
    "#     def geturl(self):\n",
    "#         return self.url\n",
    "    \n",
    "#     def getsource(self):\n",
    "#         driver.get(self.url)\n",
    "#         time.sleep(3)\n",
    "#         self.source = driver.page_source\n",
    "#         i = 0\n",
    "#         while antibot(self.source) and i<3:\n",
    "#             print('Robot! Refreshing {}/{}'.format(i,3))\n",
    "#             i += 1\n",
    "#         if antibot(self.source):\n",
    "#             raise RobotError\n",
    "#         soup = BeautifulSoup(self.source, 'lxml')\n",
    "#         sales_link = soup.find_all(class_=\"tabset-content\")[1].attrs['se:url']\n",
    "#         return sales_link\n",
    "    \n",
    "#     def getCachedSource(self):\n",
    "#         cache_url = 'https://webcache.googleusercontent.com/search?q=cache:'+self.url\n",
    "#         driver.get(cache_url)\n",
    "#         time.sleep(3)\n",
    "#         self.source = driver.page_source\n",
    "#         if antibot(self.source):\n",
    "#             raise RobotError\n",
    "#         soup = BeautifulSoup(self.source, 'lxml')\n",
    "#         sales_link = soup.find_all(class_=\"tabset-content\")[1].attrs['se:url']\n",
    "#         return sales_link\n",
    "    \n",
    "# def getTable(sales_link):\n",
    "#     driver.get('https://streeteasy.com'+sales_link)\n",
    "#     time.sleep(3)\n",
    "#     raw = driver.page_source\n",
    "#     if antibot(raw):\n",
    "#         raise RobotError\n",
    "#     soup = BeautifulSoup(raw, 'lxml')\n",
    "#     d = soup.find_all(class_='activity_date')\n",
    "#     table = soup.find_all('tr', class_='activity item')\n",
    "#     date, price, id_, unit, beds, baths, ft2 = [],[],[],[],[],[],[]\n",
    "#     for i,x in enumerate(table):\n",
    "#         cur_id = x.attrs['id']\n",
    "#         if 'sale' in cur_id: continue\n",
    "#         date.append(d[i].text.split()[0])\n",
    "#         id_.append(cur_id)\n",
    "#         hidden_group = x.find_all(class_='hidden-xs')\n",
    "#         price.append(x.find_all('td')[2].attrs['data-sort-value'])\n",
    "#         unit.append(' '.join(hidden_group[0].text.split()))\n",
    "#         beds.append(hidden_group[2].attrs['data-sort-value'])            \n",
    "#         baths.append(hidden_group[3].attrs['data-sort-value'])\n",
    "#         ft2.append(hidden_group[4].text.split()[0])\n",
    "#     data = pd.DataFrame([date, price, id_, unit, beds, baths, ft2]).T\n",
    "#     data.columns = ['date', 'price', 'id', 'unit', 'beds', 'baths', 'square feets']\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把unique的地址找出来\n",
    "# data = pd.read_csv('Geometry.csv')\n",
    "# uniqadd = data['ADDRESS'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataFL = {}\n",
    "# 先load已有的数据，避免重复查找。这里是一个以地址为key，value是一个pandas DataFrame -》感兴趣的话可以看一眼，变量名叫dataFL\n",
    "import pickle\n",
    "# with open('LSF.pk','rb') as file:\n",
    "#     dataFL = pickle.load(file)\n",
    "with open(\"information.pk\",'rb') as file:\n",
    "    buildInfo = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formattext = lambda x:[i.text.strip() for i in x]\n",
    "class buildingInfo(object):\n",
    "    def __init__(self, address):\n",
    "        for i,url in enumerate(search(address, domains='streeteasy.com/building', stop=5)):\n",
    "            if 'building' in url and 'streeteasy' in url:\n",
    "                qualified = url\n",
    "                if url.count('/') == 5:\n",
    "                    qualified = '/'.join(url.split('/')[:-1])\n",
    "                if i > 0:\n",
    "                    print(address, qualified)\n",
    "                break\n",
    "#         try:\n",
    "        self.url = qualified\n",
    "#         except NameError:\n",
    "#             print('Cannot find address {}'.format(address))\n",
    "\n",
    "    def getCachedSource(self):\n",
    "        cache_url = 'https://webcache.googleusercontent.com/search?q=cache:'+self.url\n",
    "        driver.get(cache_url)\n",
    "        time.sleep(3)\n",
    "        self.source = driver.page_source\n",
    "        if antibot(self.source):\n",
    "            raise RobotError\n",
    "        soup = BeautifulSoup(self.source, 'lxml')\n",
    "        return soup\n",
    "    \n",
    "    def extractInfo(self, soup):\n",
    "        find_add = soup.find('article', class_=\"right-two-fifths main-info \").find('h1').text\n",
    "        try:\n",
    "            Amenities = formattext(soup.find('div', class_=\"AmenitiesBlock\").find_all('div', class_=\"Text\"))\n",
    "        except AttributeError:\n",
    "            Amenities = []\n",
    "        extraInfo = formattext(soup.find('table', class_=\"clean_table legible\").find_all('span')[:3])\n",
    "        return find_add, Amenities, extraInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Amen2Dummy(Amenities_list):\n",
    "    doorman = {'Doorman','Full-time Doorman','Part-time Doorman'}\n",
    "    return ['Elevator' in Amenities_list, len(set(Amenities_list)&doorman)>0]\n",
    "def Extra2Num(Extra_list):\n",
    "    a,b,c = Extra_list\n",
    "    a = a.split()[0]\n",
    "    b = b.split()[0]\n",
    "    c = c.split()[-1]\n",
    "    return [a,b,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# buildInfo = {}\n",
    "len(buildInfo)\n",
    "# 以address为key，list分别为[elevator，doorman，unit #，stories#，building year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 West 72nd Street  Building: 330 West 72nd Street\n",
      "225 East 34th Street  Building: The Charleston\n",
      "525 East 82nd Street  Building: 525 East 82nd Street\n",
      "435 East 86th Street  Building: 435 East 86th Street\n",
      "350 East 82nd Street  Building: Wellington Tower\n",
      "321 West 13th Street  Building: 321 West 13th Street\n",
      "1001 5th Avenue  Building: 1001 Fifth Avenue\n",
      "2 Columbus Avenue  Building: 2 Columbus Avenue\n",
      "320 West 89th Street  Building: 320 West 89th Street\n",
      "Let's have a 10-min break!\n",
      "Start working\n",
      "308 East 79th Street  Building: 308 East 79th Street\n",
      "135 East 74th Street  Building: 135 East 74th Street\n",
      "209 East 56th Street  Building: 209 East 56th Street\n",
      "29 West 65  Building: Robin Court\n",
      "11 East 36th Street  Building: Morgan Lofts\n",
      "301 E 69th Street  Building: The Mayfair\n",
      "430 East 87th Street  Building: 430 East 87th Street\n",
      "49 West 96th Street  Building: 49 West 96th Street\n",
      "215 East 96th Street  Building: One Carnegie Hill\n",
      "333 Rector Place  Building: 1 Rector Park\n",
      "551 West 160th Street  Building: 551 West 160th Street\n",
      "150 East 27  Building: 150 East 27th Street\n",
      "50 West 15th Street  Building: The Oculus Condominium\n",
      "126 West 22nd Street  Building: 126 West 22nd Street\n",
      "167 West 133rd Street  House: 167 West 133rd Street\n",
      "60 Gramercy Park North  Building: 60 Gramercy Park North\n",
      "200 East 57th Street  Building: 200 East 57th Street\n",
      "456 West 167th Street  Building: Edgecombe Parc\n",
      "42 West 9th Street  Building: The Portsmouth\n",
      "105 West 13th Street  Building: 105 West 13th Street\n",
      "315 West 70th Street  Building: 315 West 70th Street\n",
      "325 West 21st Street  Building: 325 West 21st Street\n",
      "101 Central Park West  Building: 101 Central Park West\n",
      "Not found:320 East 42nd Street PH-3206\n",
      "160 E 27th Street  Building: 160 East 27th Street\n",
      "301 West 108th Street  Building: 301 West 108th Street\n",
      "310 West 72nd Street  Building: 310 West 72nd Street\n",
      "829 Park Avenue  Building: 829 Park Avenue\n",
      "130 Water Street  Building: 130 Water Street\n",
      "301 East 48th Street  Building: 301 East 48th Street\n",
      "110 East 57th Street  Building: The Dorchester\n",
      "473 Fdr Drive  Building: East River Coop\n",
      "95 Lexington Avenue  Building: 85-95 Lexington Avenue\n",
      "505 Greenwich Street  Building: 505 Greenwich Street\n",
      "111 Central Park North  Building: 111 Central Park North\n",
      "124 West 131st Street  Building: 124 West 131st Street\n",
      "80 East End Avenue  Building: 80 East End Avenue\n",
      "40 W 116  Building: Kalahari\n",
      "446 West 47th Street  Building: 446 West 47th Street\n",
      "30 East 9th Street  Building: The Lafayette\n",
      "16 West 40th Street  Building: The Bryant\n",
      "Let's have a 10-min break!\n"
     ]
    }
   ],
   "source": [
    "while len(buildInfo)<len(uniq_add):\n",
    "    try:\n",
    "        for add in uniq_add:\n",
    "            if add in buildInfo: continue\n",
    "#             time.sleep(10)\n",
    "            bc = buildingInfo(add)\n",
    "            soup = bc.getCachedSource()\n",
    "            find_add, Amenities, extraInfo = bc.extractInfo(soup)\n",
    "            print(add, find_add)\n",
    "            buildInfo[add]=Amen2Dummy(Amenities)+Extra2Num(extraInfo)\n",
    "    except (NameError, AttributeError) as e:\n",
    "        print('Not found:{}'.format(add))\n",
    "        buildInfo[add]=[0,0,0,0,0]\n",
    "    except RobotError:\n",
    "        print(\"I'm a robot! Stop at {}.\".format(add))\n",
    "        for i in range(20):\n",
    "            time.sleep(60)\n",
    "            print(i+1,end=' ')\n",
    "    except HTTPError:\n",
    "        print(\"Let's have a 10-min break!\")\n",
    "        time.sleep(600)\n",
    "        print(\"Start working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(\"information.pk\", 'wb')\n",
    "pickle.dump(buildInfo,file)\n",
    "file.close()\n",
    "if len(buildInfo)==len(uniq_add):\n",
    "    print('Done! Backup is saved as information.pk')\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'60 Warren Street '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If you find any missing information in the website, for example: https://streeteasy.com/building/2554-frederick-douglass-boulevard-new_york\n",
    "# initialize the buildInfo[add] to zeros\n",
    "# 54,8,2006\n",
    "buildInfo[add] = [True,True,'5','9','1915']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub['elevator'],data_sub['doorman'],data_sub['unit#'],data_sub['stories#'],data_sub['building year'] = 0,0,0,0,0\n",
    "for i in data_sub.index:\n",
    "    add = data_sub.loc[i,'address']\n",
    "    if add in buildInfo:\n",
    "        data_sub.loc[i, ['elevator','doorman','unit#','stories#','building year']] = buildInfo[add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_sub.to_excel('data_sub_Jieyu.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 就Run以上部分就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# link_dict = {}\n",
    "# 第一步，获取动态表格的链接\n",
    "while len(link_dict)<len(uniqadd):\n",
    "    try:\n",
    "        for x in uniqadd:\n",
    "            if x in link_dict: continue\n",
    "            obj = AddressInfo(x)\n",
    "            link = obj.getCachedSource()\n",
    "#             link = obj.getsource()\n",
    "            link_dict[x]=link\n",
    "            time.sleep(5)\n",
    "    except RobotError:\n",
    "        print(\"I'm a robot! Stop at {}.\".format(x))\n",
    "        break\n",
    "    except IndexError:\n",
    "        print(\"Not Found: {}\".format(x))\n",
    "        link_dict[x]= 'NotFound'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#只要数据不够就一直跑，直到被认为是机器人\n",
    "while len(dataFL)<len(link_dict):\n",
    "    try:\n",
    "        for x in uniqadd:\n",
    "            if x in dataFL: continue\n",
    "#             obj = AddressInfo()\n",
    "#             link = obj.getsource()\n",
    "            link = link_dict[x]\n",
    "            if link == 'NotFound':\n",
    "                dataFL[x]=None\n",
    "                continue\n",
    "            dataFL[x]=getTable(link)\n",
    "            time.sleep(10)     \n",
    "    except RobotError:\n",
    "        print(\"I'm a robot! Stop at {}.\".format(x))\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Check link to see what is going on:\\n{}'.format('https://streeteasy.com'+link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for x in list(link_dict):\n",
    "#     if link_dict[x] == 'NotFound':\n",
    "#         link_dict.pop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if len(link_dict) == len(dataFL):\n",
    "    print(len(link_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(link_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFL[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(uniqadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close()\n",
    "\n",
    "file = open(\"LSF.pk\", 'wb')\n",
    "pickle.dump(dataFL,file)\n",
    "file.close()\n",
    "\n",
    "file = open(\"building_idx.pk\", 'wb')\n",
    "pickle.dump(link_dict,file)\n",
    "file.close()\n",
    "# 即时保存，避免出意外。这个class会print出来所用的网址，也可以扫一眼看看有没有问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([['07/16/2018','11/02/2017'], ['$384,000','$379,000'], [None ,None], ['#3D', '#5D'], ['2','2'], ['1','0'], ['425','450']]).T\n",
    "data.columns = ['date', 'price', 'id', 'unit', 'beds', 'baths', 'square feets']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFL[x]=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from googlesearch import search\n",
    "for url in search(' 518 EAST 11TH STREET', stop=50):\n",
    "    print(url)\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# html_http_response = requests.get(\"https://therealdeal.com/new-research/topics/property/613-east-6th-street/\", cookies=cookies)\n",
    "# data = html_http_response.text\n",
    "soup = BeautifulSoup(html_doc, 'lxml')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soupff = BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales_link = soupff.find_all(class_=\"tabset-content\")[1].attrs['se:url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.get('https://streeteasy.com'+sales_link)\n",
    "time.sleep(3)\n",
    "raw = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soupraw = BeautifulSoup(raw, 'lxml')\n",
    "d = soupraw.find_all(class_='activity_date')\n",
    "table = soupraw.find_all('tr', class_='activity item')\n",
    "pri = soupraw.find_all('span',class_=\"price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "' '.join(table[0].find_all(class_='hidden-xs')[0].text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "' '.join(['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(2.0 == 1 or 2.0 == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = search('245 West 19th Street'+'streeteasy', stop=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('url_list.txt', 'w') as f:\n",
    "    for i in range(50,1200):\n",
    "        print('https://streeteasy.com/for-sale/manhattan/status:sold?page='+str(i), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Directly from Streeteasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2t = lambda x: [i.text for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# address = {}\n",
    "# location = {}\n",
    "# details = {}\n",
    "# price = {}\n",
    "path = [x for x in range(51,1200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while len(path)>0:\n",
    "    try:\n",
    "        page = path.pop()\n",
    "        link = 'https://streeteasy.com/for-sale/manhattan/status:sold?page='+str(page)\n",
    "        driver.get(link)\n",
    "        time.sleep(5)\n",
    "        source = driver.page_source\n",
    "        if antibot(source):\n",
    "            raise RobotError\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        items = soup.find_all('article')\n",
    "        for i in range(len(items)):\n",
    "            if (page, i) in price: continue\n",
    "            location[(page, i)] = items[i].attrs['se:map:point']\n",
    "            address[(page, i)] = items[i].find(class_='details-title').find('a').text\n",
    "            try:\n",
    "                details[(page, i)] = l2t(items[i].find(class_='details_info details-info-flex').find_all('li'))\n",
    "            except AttributeError:\n",
    "                details[(page, i)] = None\n",
    "            price[(page, i)] = items[i].find(class_='price').text\n",
    "    except RobotError:\n",
    "        print(\"I'm a robot! Stop at {}.\".format(page))\n",
    "        path.append(page)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame([location, address, details, price]).T\n",
    "data.columns = ['location', 'address', 'details', 'price']\n",
    "data.head(),len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# driver.close()\n",
    "data.to_excel('Sales_SE.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save((address, location, details, price, path), 'HHHH.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "address, location, details, price, path = torch.load('HHHH.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('Sales_SE.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['details'][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bed = r'^([1-9])\\sbed(s)?'\n",
    "bath = r'^([0-9](.5)?)(\\+)?\\sbath(s)?'\n",
    "ft = r'^([0-9]+(,)?[0-9]+)\\sft.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def listextr(cell,matchtype):\n",
    "    for x in cell:\n",
    "        m = re.match(matchtype, x)\n",
    "        if re.match(matchtype, x):\n",
    "            return m.group(1)\n",
    "    return None\n",
    "bed_match = partial(listextr, matchtype=bed)\n",
    "bath_match = partial(listextr, matchtype=bath)\n",
    "ft_match = partial(listextr, matchtype=ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['details'][5152],bed_match(data['details'][5152]),bath_match(data['details'][5152]),ft_match(data['details'][5152])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['#beds'] = data['details'].map(bed_match, na_action='ignore')\n",
    "data['#baths'] = data['details'].map(bath_match, na_action='ignore')\n",
    "data['#square_feet'] = data['details'].map(ft_match, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_excel('Sales_SE.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['details'] = add.map(ast.literal_eval, na_action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.loc[5539,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
